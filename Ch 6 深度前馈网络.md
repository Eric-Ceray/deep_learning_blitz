# Ch 6 深度前馈网络

MLP是典型的深度学习模型，目的是近似某个函数。

MLP是前向的，因为在模型的输出和模型本身之间没有反馈连接。

当MLP被扩展成包含反馈连接时，它们被称为循环神经网络RNN。

MLP是RNN的基石，后者在NLP中发挥着巨大作用。

通过学习特征来改善模型的一般化特征。

## 6.1 实例：学习XOR

## 6.2 基于梯度的学习

神经网络中的非线性造成了损失函数的非凸化。

使用于非凸函数的SGD不能保证收敛，并且对于参数初值非常敏感。

对于fnn，weights的初值必须是很小的随机量。bias的初值必须是0或者很小的正值。

### 6.2.1 损失函数

#### 6.2.1.1 MLE学习条件分布

$$
J(\pmb\theta)=-\mathbb{E}_{\pmb x,\pmb y\sim\hat p_{data}}\log p_{\text{model}}(y|x)
$$

#### 6.2.1.2 学习条件随机变量

### 6.2.2 输出单元

很多时候损失函数直接选择交叉熵。

#### 6.2.2.1 针对高斯输出分布的线性单元

线性输出层经常被用来产生条件高斯分布的均值：
$$
p(y|x)=\mathcal{N}(y;\hat y,I)
$$




